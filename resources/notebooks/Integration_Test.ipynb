{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9392 DataNode\n",
      "10050 NodeManager\n",
      "9635 SecondaryNameNode\n",
      "9188 NameNode\n",
      "10613 RunJar\n",
      "10614 RunJar\n",
      "10583 JobHistoryServer\n",
      "11641 Jps\n",
      "10494 WebAppProxyServer\n",
      "9855 ResourceManager\n"
     ]
    }
   ],
   "source": [
    "!jps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example.csv\n"
     ]
    }
   ],
   "source": [
    "%%file example.csv\n",
    "id,firstname,lastname,email,profession\n",
    "100,Allyce,Dom,Allyce.Dom@gmail.com,firefighter\n",
    "101,Gertrud,Poppy,Gertrud.Poppy@gmail.com,worker\n",
    "102,Jacquetta,Sigfrid,Jacquetta.Sigfrid@gmail.com,worker\n",
    "103,Desirae,Mich,Desirae.Mich@gmail.com,firefighter\n",
    "104,Kalina,Edee,Kalina.Edee@gmail.com,firefighter\n",
    "105,Bibby,Raffo,Bibby.Raffo@gmail.com,developer\n",
    "106,Maisey,Erlandson,Maisey.Erlandson@gmail.com,firefighter\n",
    "107,Adriana,Deegan,Adriana.Deegan@gmail.com,firefighter\n",
    "108,Eve,Durante,Eve.Durante@gmail.com,developer\n",
    "109,Clarice,Robertson,Clarice.Robertson@gmail.com,firefighter\n",
    "110,Patricia,Alexandr,Patricia.Alexandr@gmail.com,firefighter\n",
    "111,Eolanda,Ursulette,Eolanda.Ursulette@gmail.com,developer\n",
    "112,Nannie,Ilka,Nannie.Ilka@gmail.com,doctor\n",
    "113,Dagmar,Mauer,Dagmar.Mauer@gmail.com,police officer\n",
    "114,Shaylyn,Mich,Shaylyn.Mich@gmail.com,developer\n",
    "115,Gilda,Daveta,Gilda.Daveta@gmail.com,worker\n",
    "116,Carree,Faust,Carree.Faust@gmail.com,police officer\n",
    "117,Collen,Kaete,Collen.Kaete@gmail.com,developer\n",
    "118,Gloria,Bendick,Gloria.Bendick@gmail.com,worker\n",
    "119,Kary,Eachern,Kary.Eachern@gmail.com,developer\n",
    "120,Margette,Therine,Margette.Therine@gmail.com,doctor\n",
    "121,Nataline,Kosey,Nataline.Kosey@gmail.com,developer\n",
    "122,Romona,Ludewig,Romona.Ludewig@gmail.com,firefighter\n",
    "123,Eadie,Tyson,Eadie.Tyson@gmail.com,police officer\n",
    "124,Jan,Geffner,Jan.Geffner@gmail.com,worker\n",
    "125,Corina,Tomasina,Corina.Tomasina@gmail.com,police officer\n",
    "126,Ellette,Bearnard,Ellette.Bearnard@gmail.com,firefighter\n",
    "127,Marinna,Peg,Marinna.Peg@gmail.com,worker\n",
    "128,Brana,Burnside,Brana.Burnside@gmail.com,worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -mkdir -p /user/vagrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -put example.csv /user/vagrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   1 vagrant supergroup       1574 2020-06-19 13:26 /user/vagrant/example.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/vagrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_hive.hql\n"
     ]
    }
   ],
   "source": [
    "%%file test_hive.hql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS test_table\n",
    " (col1 int COMMENT 'Integer Column',\n",
    " col2 string COMMENT 'String Column')\n",
    " COMMENT 'This is test table'\n",
    " ROW FORMAT DELIMITED\n",
    " FIELDS TERMINATED BY ','\n",
    " STORED AS TEXTFILE;\n",
    "    \n",
    "INSERT INTO test_table VALUES(1,'testing');\n",
    "\n",
    "SELECT * FROM test_table;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to jdbc:hive2://10.0.2.15:10000\n",
      "2020-06-19 13:15:50,412 INFO jdbc.Utils: Supplied authorities: 10.0.2.15:10000\n",
      "2020-06-19 13:15:50,413 INFO jdbc.Utils: Resolved authority: 10.0.2.15:10000\n",
      "Connected to: Apache Hive (version 3.1.2)\n",
      "Driver: Hive JDBC (version 2.3.7)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "0: jdbc:hive2://10.0.2.15:10000> \n",
      "0: jdbc:hive2://10.0.2.15:10000> CREATE TABLE IF NOT EXISTS test_table\n",
      ". . . . . . . . . . . . . . . .>  (col1 int COMMENT 'Integer Column',\n",
      ". . . . . . . . . . . . . . . .>  col2 string COMMENT 'String Column')\n",
      ". . . . . . . . . . . . . . . .>  COMMENT 'This is test table'\n",
      ". . . . . . . . . . . . . . . .>  ROW FORMAT DELIMITED\n",
      ". . . . . . . . . . . . . . . .>  FIELDS TERMINATED BY ','\n",
      ". . . . . . . . . . . . . . . .>  STORED AS TEXTFILE;\n",
      "INFO  : Compiling command(queryId=vagrant_20200619131550_07fe98a3-4386-48dc-8174-a2bc58834924): CREATE TABLE IF NOT EXISTS test_table\n",
      "(col1 int COMMENT 'Integer Column',\n",
      "col2 string COMMENT 'String Column')\n",
      "COMMENT 'This is test table'\n",
      "ROW FORMAT DELIMITED\n",
      "FIELDS TERMINATED BY ','\n",
      "STORED AS TEXTFILE\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)\n",
      "INFO  : Completed compiling command(queryId=vagrant_20200619131550_07fe98a3-4386-48dc-8174-a2bc58834924); Time taken: 0.765 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=vagrant_20200619131550_07fe98a3-4386-48dc-8174-a2bc58834924): CREATE TABLE IF NOT EXISTS test_table\n",
      "(col1 int COMMENT 'Integer Column',\n",
      "col2 string COMMENT 'String Column')\n",
      "COMMENT 'This is test table'\n",
      "ROW FORMAT DELIMITED\n",
      "FIELDS TERMINATED BY ','\n",
      "STORED AS TEXTFILE\n",
      "INFO  : Starting task [Stage-0:DDL] in serial mode\n",
      "INFO  : Completed executing command(queryId=vagrant_20200619131550_07fe98a3-4386-48dc-8174-a2bc58834924); Time taken: 0.483 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (1.466 seconds)\n",
      "0: jdbc:hive2://10.0.2.15:10000>     \n",
      "0: jdbc:hive2://10.0.2.15:10000> INSERT INTO test_table VALUES(1,'testing');\n",
      "INFO  : Compiling command(queryId=vagrant_20200619131552_468ee77f-e381-4c37-ae98-3bff663b54f5): INSERT INTO test_table VALUES(1,'testing')\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:col1, type:int, comment:null), FieldSchema(name:col2, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=vagrant_20200619131552_468ee77f-e381-4c37-ae98-3bff663b54f5); Time taken: 2.653 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=vagrant_20200619131552_468ee77f-e381-4c37-ae98-3bff663b54f5): INSERT INTO test_table VALUES(1,'testing')\n",
      "WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "INFO  : Query ID = vagrant_20200619131552_468ee77f-e381-4c37-ae98-3bff663b54f5\n",
      "INFO  : Total jobs = 3\n",
      "INFO  : Launching Job 1 out of 3\n",
      "INFO  : Starting task [Stage-1:MAPRED] in serial mode\n",
      "INFO  : Number of reduce tasks determined at compile time: 1\n",
      "INFO  : In order to change the average load for a reducer (in bytes):\n",
      "INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "INFO  : In order to limit the maximum number of reducers:\n",
      "INFO  :   set hive.exec.reducers.max=<number>\n",
      "INFO  : In order to set a constant number of reducers:\n",
      "INFO  :   set mapreduce.job.reduces=<number>\n",
      "INFO  : number of splits:1\n",
      "INFO  : Submitting tokens for job: job_1592572147865_0001\n",
      "INFO  : Executing with tokens: []\n",
      "INFO  : The url to track the job: http://0.0.0.0:9046/proxy/application_1592572147865_0001/\n",
      "INFO  : Starting Job = job_1592572147865_0001, Tracking URL = http://0.0.0.0:9046/proxy/application_1592572147865_0001/\n",
      "INFO  : Kill Command = /opt/hadoop/bin/mapred job  -kill job_1592572147865_0001\n",
      "INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "INFO  : 2020-06-19 13:16:04,581 Stage-1 map = 0%,  reduce = 0%\n",
      "INFO  : 2020-06-19 13:16:09,849 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.05 sec\n",
      "INFO  : 2020-06-19 13:16:15,224 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.48 sec\n",
      "INFO  : MapReduce Total cumulative CPU time: 3 seconds 480 msec\n",
      "INFO  : Ended Job = job_1592572147865_0001\n",
      "INFO  : Starting task [Stage-7:CONDITIONAL] in serial mode\n",
      "INFO  : Stage-4 is selected by condition resolver.\n",
      "INFO  : Stage-3 is filtered out by condition resolver.\n",
      "INFO  : Stage-5 is filtered out by condition resolver.\n",
      "INFO  : Starting task [Stage-4:MOVE] in serial mode\n",
      "INFO  : Moving data to directory hdfs://10.211.55.101:9000/user/hive/warehouse/test_table/.hive-staging_hive_2020-06-19_13-15-52_225_1421096779157662988-1/-ext-10000 from hdfs://10.211.55.101:9000/user/hive/warehouse/test_table/.hive-staging_hive_2020-06-19_13-15-52_225_1421096779157662988-1/-ext-10002\n",
      "INFO  : Starting task [Stage-0:MOVE] in serial mode\n",
      "INFO  : Loading data to table default.test_table from hdfs://10.211.55.101:9000/user/hive/warehouse/test_table/.hive-staging_hive_2020-06-19_13-15-52_225_1421096779157662988-1/-ext-10000\n",
      "INFO  : Starting task [Stage-2:STATS] in serial mode\n",
      "INFO  : MapReduce Jobs Launched: \n",
      "INFO  : Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.48 sec   HDFS Read: 15574 HDFS Write: 247 SUCCESS\n",
      "INFO  : Total MapReduce CPU Time Spent: 3 seconds 480 msec\n",
      "INFO  : Completed executing command(queryId=vagrant_20200619131552_468ee77f-e381-4c37-ae98-3bff663b54f5); Time taken: 23.151 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "No rows affected (25.827 seconds)\n",
      "0: jdbc:hive2://10.0.2.15:10000> \n",
      "0: jdbc:hive2://10.0.2.15:10000> SELECT * FROM test_table;\n",
      "INFO  : Compiling command(queryId=vagrant_20200619131618_9fa23df3-c9bb-457a-bd55-8a24fe63807f): SELECT * FROM test_table\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Semantic Analysis Completed (retrial = false)\n",
      "INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:test_table.col1, type:int, comment:null), FieldSchema(name:test_table.col2, type:string, comment:null)], properties:null)\n",
      "INFO  : Completed compiling command(queryId=vagrant_20200619131618_9fa23df3-c9bb-457a-bd55-8a24fe63807f); Time taken: 0.387 seconds\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "INFO  : Executing command(queryId=vagrant_20200619131618_9fa23df3-c9bb-457a-bd55-8a24fe63807f): SELECT * FROM test_table\n",
      "INFO  : Completed executing command(queryId=vagrant_20200619131618_9fa23df3-c9bb-457a-bd55-8a24fe63807f); Time taken: 0.0 seconds\n",
      "INFO  : OK\n",
      "INFO  : Concurrency mode is disabled, not creating a lock manager\n",
      "+------------------+------------------+\n",
      "| test_table.col1  | test_table.col2  |\n",
      "+------------------+------------------+\n",
      "| 1                | testing          |\n",
      "+------------------+------------------+\n",
      "1 row selected (0.506 seconds)\n",
      "0: jdbc:hive2://10.0.2.15:10000> \n",
      "0: jdbc:hive2://10.0.2.15:10000> Closing: 0: jdbc:hive2://10.0.2.15:10000\n"
     ]
    }
   ],
   "source": [
    "!beeline -u jdbc:hive2://10.0.2.15:10000 -f ./test_hive.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql mysql://hive:3MX6fDLN2AQm23bD@localhost/metastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql://hive:***@localhost/metastore\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>TBL_ID</th>\n",
       "        <th>CREATE_TIME</th>\n",
       "        <th>OWNER</th>\n",
       "        <th>TBL_NAME</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>1592572551</td>\n",
       "        <td>vagrant</td>\n",
       "        <td>test_table</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1, 1592572551, 'vagrant', 'test_table')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select TBL_ID, CREATE_TIME, OWNER, TBL_NAME\n",
    "from TBLS;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "appName = \"Integration Test\"\n",
    "master = \"spark://localhost:7077\"\n",
    "conf = SparkConf() \\\n",
    "    .set('spark.sql.catalogImplementation', 'hive') \\\n",
    "    .setAppName(appName) \\\n",
    "    .setMaster(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://localhost:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Integration Test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://localhost:7077 appName=Integration Test>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import HiveContext\n",
    "hc = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+\n",
      "|database| tableName|isTemporary|\n",
      "+--------+----------+-----------+\n",
      "| default|test_table|      false|\n",
      "+--------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hc.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|col1|   col2|\n",
      "+----+-------+\n",
      "|   1|testing|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hc.sql(\"select * from test_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "    \n",
    "sparksession = SparkSession.builder.appName(\"example-pyspark-read-and-write\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (sparksession\n",
    "\t.read\n",
    "\t.format(\"csv\")\n",
    "\t.option(\"header\", \"true\")\n",
    "\t.load(\"hdfs://10.211.55.101:9000/user/vagrant/example.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+--------------------+--------------+\n",
      "| id|firstname| lastname|               email|    profession|\n",
      "+---+---------+---------+--------------------+--------------+\n",
      "|100|   Allyce|      Dom|Allyce.Dom@gmail.com|   firefighter|\n",
      "|101|  Gertrud|    Poppy|Gertrud.Poppy@gma...|        worker|\n",
      "|102|Jacquetta|  Sigfrid|Jacquetta.Sigfrid...|        worker|\n",
      "|103|  Desirae|     Mich|Desirae.Mich@gmai...|   firefighter|\n",
      "|104|   Kalina|     Edee|Kalina.Edee@gmail...|   firefighter|\n",
      "|105|    Bibby|    Raffo|Bibby.Raffo@gmail...|     developer|\n",
      "|106|   Maisey|Erlandson|Maisey.Erlandson@...|   firefighter|\n",
      "|107|  Adriana|   Deegan|Adriana.Deegan@gm...|   firefighter|\n",
      "|108|      Eve|  Durante|Eve.Durante@gmail...|     developer|\n",
      "|109|  Clarice|Robertson|Clarice.Robertson...|   firefighter|\n",
      "|110| Patricia| Alexandr|Patricia.Alexandr...|   firefighter|\n",
      "|111|  Eolanda|Ursulette|Eolanda.Ursulette...|     developer|\n",
      "|112|   Nannie|     Ilka|Nannie.Ilka@gmail...|        doctor|\n",
      "|113|   Dagmar|    Mauer|Dagmar.Mauer@gmai...|police officer|\n",
      "|114|  Shaylyn|     Mich|Shaylyn.Mich@gmai...|     developer|\n",
      "|115|    Gilda|   Daveta|Gilda.Daveta@gmai...|        worker|\n",
      "|116|   Carree|    Faust|Carree.Faust@gmai...|police officer|\n",
      "|117|   Collen|    Kaete|Collen.Kaete@gmai...|     developer|\n",
      "|118|   Gloria|  Bendick|Gloria.Bendick@gm...|        worker|\n",
      "|119|     Kary|  Eachern|Kary.Eachern@gmai...|     developer|\n",
      "+---+---------+---------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
